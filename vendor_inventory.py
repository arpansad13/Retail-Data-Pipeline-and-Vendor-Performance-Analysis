# -*- coding: utf-8 -*-
"""Vendor Inventory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6FocRE1uevPy62_kfo4AQW0LrbP8Jkn

#Importing the CSV files into Database
"""

import pandas as pd
import os
from sqlalchemy import create_engine
import logging
import time

logging.basicConfig(
    filename="content/logs/ingestion_db.log",
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.DEBUG,
    filemode="a"
)

engine = create_engine('sqlite:///inventor.db')

'''This function will ingest Data Frame into Database'''
def ingest_db(df, table_name, engine):
  df.to_sql(table_name, con = engine, if_exists='replace', index=False)

def load_raw_data():
    start_time = time.time()
    for file in os.listdir('/content'):
        if '.csv' in file:
            table_name = file[:-4]
            logging.info(f'Attempting to process file: {file}')
            try:
                logging.info(f'Starting ingestion of {file} into table {table_name}')
                # Read CSV in chunks
                chunk_size = 10000 # Reduced chunk size
                for i, chunk in enumerate(pd.read_csv(file, chunksize=chunk_size)):
                    logging.info(f'Ingesting chunk {i} of {file}')
                    try:
                        chunk.to_sql(table_name, con=engine, if_exists='append' if i > 0 else 'replace', index=False)
                        logging.info(f'Chunk {i} of {file} ingested successfully')
                    except Exception as db_error:
                        logging.error(f'Error ingesting chunk {i} of {file} into database: {db_error}')
                        # Consider breaking or continuing based on severity of db error
                logging.info(f'{file} fully ingested successfully into table {table_name}')
                print(f'{file} fully ingested successfully into table {table_name}')
            except Exception as read_error:
                logging.error(f'Error reading or processing file {file}: {read_error}')

    end_time = time.time()
    total_time = (end_time - start_time) / 60
    logging.info(f'Total time taken for ingestion: {total_time:.2f} minutes')
    print(f'Total time taken for ingestion: {total_time:.2f} minutes')

if __name__ == "__main__":
    load_raw_data()

'''This is failng due to Memory issue'''
def load_raw_data():
    start_time = time.time()
    for file in os.listdir('//content'):
        if '.csv' in file:
          df = pd.read_csv(file)
          ingest_db(df, file[:-4], engine)
          print(df.shape)
    end_time = time.time()
    total_time = (end_time - start_time) / 60
    logging.info(f'Total time taken for ingestion: {total_time:.2f} minutes')

"""# Bsaic Exploratory Data Analysis

Understanding the dataset to explore how the data is present in the database and and if there is a need of creating some aggregated tables that can help with:
*   Vendor selection for profitability
*   Product pricing Optimization
"""

import pandas as pd
import sqlite3

#creating database connection
conn = sqlite3.connect('inventor.db')
print("Opened database successfully")

#checking tables present in the database
tables = pd.read_sql_query("SELECT name FROM sqlite_master WHERE type='table';", conn)
tables

"""Let's check the total records present in each table and display few records."""

for table in tables['name']:
  print("-"*50,table,"-"*50)
  print("Count of Records",pd.read_sql(f"SELECT count(*) AS count FROM {table}", conn)['count'][0])
  display(pd.read_sql(f"SELECT * FROM {table} LIMIT 5", conn))

#Checking the datasets for the random vendor number 4466
vendor_invoice = pd.read_sql("SELECT * FROM vendor_invoice WHERE VendorNumber = 4466",conn)
purchase_prices = pd.read_sql("SELECT * FROM purchase_prices WHERE VendorNumber = 4466",conn)
purchases = pd.read_sql("SELECT * FROM purchases WHERE VendorNumber = 4466",conn)
sales = pd.read_sql("SELECT * FROM sales WHERE VendorNo = 4466",conn)

purchases.groupby(['Brand','PurchasePrice'])[['Quantity','Dollars']].sum()

sales.groupby(['Brand'])[['SalesPrice','SalesQuantity','SalesDollars']].sum()

"""*   The purchases table contains actual purchase data, including the date of purchase, products(brands) purchased by vendors, the amount paid (in dollars), and the quantity purchased.
*   The purchase price column is derived from the purchase_prices table, which provides product-wise actual and purchase prices. The combination of vendor and brand is unique in this table.
*   The vendor_invoice table aggregates data from the purchases table, summarizing quantity and dollar amounts, along with and additional column for freight. This table maintains uniqueness based on vendor and PO number.
*   The sales table captures actual sales transactions, detailing the brands purchased by vendors, the quantity sold, the selling price, and the revenue earned.

As the data that we need for the analysis is distributed in different tables, we need to create a summary table containing:
*   purchase transactions made by vendors
*   sales transaction data
*   freight costs for each vendor.
*   actual product prices from vendors.
"""

vendor_invoice.columns

pd.read_sql('''SELECT VendorNumber, SUM(Quantity) AS total_quantity,
SUM(Dollars) AS total_dollars, SUM(Freight) AS total_freight
FROM vendor_invoice GROUP BY VendorNumber''', conn)

purchase_prices.columns

purchases.columns

pd.read_sql('''SELECT p.VendorNumber, p.VendorName,
p.Brand, p.PurchasePrice,
pp.Volume AS volume, pp.Price AS actual_price,
SUM(p.Quantity) AS total_purchase_quantity,
SUM(p.Dollars) AS total_purchase_dollars
FROM purchases p
JOIN purchase_prices pp ON p.Brand = pp.Brand
WHERE p.PurchasePrice > 0
GROUP BY p.VendorNumber, p.VendorName, p.Brand''', conn)

sales.columns

pd.read_sql('''SELECT VendorNo, Brand,
SUM(SalesPrice) AS total_sales_price,
SUM(SalesQuantity) AS total_sales_quantity,
SUM(SalesDollars) AS total_sales_dollars,
SUM(ExciseTax) AS total_ExciseTax
FROM sales GROUP BY VendorNo, Brand''', conn)

#Taking the entire tables
vendor_invoice = pd.read_sql("SELECT * FROM vendor_invoice",conn)
purchase_prices = pd.read_sql("SELECT * FROM purchase_prices",conn)
purchases = pd.read_sql("SELECT * FROM purchases",conn)

chunk_size = 1000000  # Defined a suitable chunk size
all_sales_chunks = [] # Initialize an empty list to store the chunks

# Iterate over chunks of the sales table
for i, sales_chunk in enumerate(pd.read_sql("SELECT * FROM sales", conn, chunksize=chunk_size)):
    print(f"Processing chunk {i+1}, containing {len(sales_chunk)} rows.")

    # Append the current chunk to the list
    all_sales_chunks.append(sales_chunk)

# Concatenate all the chunks into a single DataFrame after the loop
# Be aware that this step will still require enough memory to hold the final DataFrame
try:
    sales = pd.concat(all_sales_chunks, ignore_index=True)
    print("\nSuccessfully combined all chunks into the 'sales' DataFrame.")
    print(f"Shape of the final sales DataFrame: {sales.shape}")
except Exception as e:
    print(f"\nError concatenating chunks: {e}")
    print("This might still be a memory issue if the combined DataFrame is too large.")

#This query is taking lot of time to execute so we will optimize this query
final_table = pd.read_sql_query('''
SELECT pp.VendorNumber,
pp.Brand,
pp.Price AS ActualPrice,
pp.PurchasePrice,
SUM(s.SalesQuantity) AS TotslSalesQuantity,
SUM(s.SalesDollars) AS TotalSalesDollar,
SUM(s.SalesPrice) AS TotalSalesPrice,
SUM(s.ExciseTax) AS TotalExciseTax,
SUM(vi.Quantity) AS TotalPurchaseQuantity,
SUM(vi.Dollars) AS TotalPurchaseDollars,
SUM(vi.Freight) AS TotalFreightCost
FROM purchase_prices pp
JOIN sales s
ON pp.VendorNumber = s.VendorNo
AND pp.Brand = s.Brand
JOIN vendor_invoice vi
ON pp.VendorNumber = vi.VendorNumber
GROUP BY pp.VendorNumber, pp.Brand, pp.Price, pp.PurchasePrice
''',conn)

import time
start_time = time.time()
vendor_sales_summary = pd.read_sql_query('''WITH FreightSummary AS (
    SELECT VendorNumber, SUM(Freight) AS FreightCost
    FROM vendor_invoice
    GROUP BY VendorNumber
),

PurchaseSummary AS (
    SELECT p.VendorNumber,
    p.VendorName,
    p.Brand,
    p.Description,
    p.PurchasePrice,
    pp.Price AS ActualPrice,
    pp.Volume AS Volume,
    SUM(p.Quantity) AS TotalPurchaseQuantity,
    SUM(p.Dollars) AS TotalPurchaseDollars
    FROM purchases p
    JOIN purchase_prices pp ON p.Brand = pp.Brand
    WHERE p.PurchasePrice > 0
    GROUP BY p.VendorNumber, p.VendorName, p.Brand, p.Description, p.PurchasePrice, pp.Price, pp.Volume),

SalesSummary AS (
  SELECT VendorNo, Brand,
  SUM(SalesPrice) AS TotalSalesPrice,
  SUM(SalesQuantity) AS TotalSalesQuantity,
  SUM(SalesDollars) AS TotalSalesDollars,
  SUM(ExciseTax) AS TotalExciseTax
  FROM sales
  GROUP BY VendorNo, Brand
)

SELECT
ps.VendorNumber,
ps.VendorName,
ps.Brand,
ps.Description,
ps.PurchasePrice,
ps.ActualPrice,
ps.Volume,
ps.TotalPurchaseQuantity,
ps.TotalPurchaseDollars,
ss.TotalSalesPrice,
ss.TotalSalesQuantity,
ss.TotalSalesDollars,
ss.TotalExciseTax,
fs.FreightCost
FROM PurchaseSummary ps
LEFT JOIN SalesSummary ss ON ps.VendorNumber = ss.VendorNo AND ps.Brand = ss.Brand
LEFT JOIN FreightSummary fs ON ps.VendorNumber = fs.VendorNumber
ORDER BY ps.TotalPurchaseDollars DESC
''',conn)

end_time = time.time()
total_time = (end_time - start_time) / 60
print(f'Total time taken for ingestion: {total_time:.2f} minutes')

vendor_sales_summary

"""This query generates a vendor-wise sales and purchase summary, which is valuable for:

**Performance Optimization:**
* The query invloves heavy joins and aggregations on large datasets like sales and purchases.
*  Storing the pre-aggregated results avoids repeated expensive computations.
*   Helps in analyzing sales, purchases, and pricing for different vendors and brands.
*   Future Benifits of Storing this data for faster Dashboarding & reporting.
*   Instead of running expensive queries each time, dashboards can fetch data quickly from vendor_sales_summary.

Now let's check if there is any incomsistancy in our final Dataset
"""

vendor_sales_summary.shape

vendor_sales_summary.dtypes

"""Volume column should be integer/float but in the dataset it is object. So we will change it."""

vendor_sales_summary['Volume'] = vendor_sales_summary['Volume'].astype('float64')

vendor_sales_summary.dtypes

vendor_sales_summary['VendorName'].unique()

"""There are some extra spaces in the "VendorName" column so we will remove it."""

vendor_sales_summary['VendorName'] = vendor_sales_summary['VendorName'].str.strip()

vendor_sales_summary.isnull().sum()

"""We will fill the null values with 0"""

vendor_sales_summary.fillna(0, inplace=True)

vendor_sales_summary.isnull().sum()

"""Let's create some new features for our further Analysis"""

vendor_sales_summary['GrossProfit'] = vendor_sales_summary['TotalSalesDollars'] - vendor_sales_summary['TotalPurchaseDollars']

vendor_sales_summary['ProfitMargin'] = (vendor_sales_summary['GrossProfit'] / vendor_sales_summary['TotalSalesDollars']) * 100

vendor_sales_summary['StockTrunover'] = vendor_sales_summary['TotalPurchaseQuantity'] / vendor_sales_summary['TotalSalesQuantity']

vendor_sales_summary['SalesToPurchaseRatio'] = vendor_sales_summary['TotalSalesQuantity'] / vendor_sales_summary['TotalPurchaseQuantity']

vendor_sales_summary

"""Now we will insert the data into DB"""

vendor_sales_summary.columns

cursor = conn.cursor()

cursor.execute('''
  CREATE TABLE vendor_sales_summary (
        VendorNumber INTEGER,
        VendorName VARCHAR(255),
        Brand INT,
        Description VARCHAR(255),
        PurchasePrice DECIMAL(10, 2),
        ActualPrice DECIMAL(10, 2),
        Volume DECIMAL(10, 2),
        TotalPurchaseQuantity INT,
        TotalPurchaseDollars DECIMAL(15, 2),
        TotalSalesPrice DECIMAL(15, 2),
        TotalSalesQuantity INT,
        TotalSalesDollars DECIMAL(15, 2),
        TotalExciseTax DECIMAL(15, 2),
        FreightCost DECIMAL(15, 2),
        GrossProfit DECIMAL(15, 2),
        ProfitMargin DECIMAL(15, 2),
        StockTrunover DECIMAL(15, 2),
        SalesToPurchaseRatio DECIMAL(15, 2),
        PRIMARY KEY (VendorNumber, Brand)
      )
''')

#Write the data into the table
vendor_sales_summary.to_sql('vendor_sales_summary', conn, if_exists='replace', index=False)

#Checking the final table
pd.read_sql("SELECT * FROM vendor_sales_summary", conn)

"""#Get Vendor Summary Function"""

import pandas as pd
import os
from sqlalchemy import create_engine
import logging
import time

logging.basicConfig(
    filename="/content/logs/get_vendor_summary.log",
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.DEBUG,
    filemode="a"
)

def create_vendor_summary(conn):
  '''This function will merge the different tables to get the overall vendor summary and adding new columns in the resultant data'''
  start_time = time.time()
  vendor_sales_summary = pd.read_sql_query('''WITH FreightSummary AS (
    SELECT VendorNumber, SUM(Freight) AS FreightCost
    FROM vendor_invoice
    GROUP BY VendorNumber
),

PurchaseSummary AS (
    SELECT p.VendorNumber,
    p.VendorName,
    p.Brand,
    p.Description,
    p.PurchasePrice,
    pp.Price AS ActualPrice,
    pp.Volume AS Volume,
    SUM(p.Quantity) AS TotalPurchaseQuantity,
    SUM(p.Dollars) AS TotalPurchaseDollars
    FROM purchases p
    JOIN purchase_prices pp ON p.Brand = pp.Brand
    WHERE p.PurchasePrice > 0
    GROUP BY p.VendorNumber, p.VendorName, p.Brand, p.Description, p.PurchasePrice, pp.Price, pp.Volume),

SalesSummary AS (
  SELECT VendorNo, Brand,
  SUM(SalesPrice) AS TotalSalesPrice,
  SUM(SalesQuantity) AS TotalSalesQuantity,
  SUM(SalesDollars) AS TotalSalesDollars,
  SUM(ExciseTax) AS TotalExciseTax
  FROM sales
  GROUP BY VendorNo, Brand
)

SELECT
ps.VendorNumber,
ps.VendorName,
ps.Brand,
ps.Description,
ps.PurchasePrice,
ps.ActualPrice,
ps.Volume,
ps.TotalPurchaseQuantity,
ps.TotalPurchaseDollars,
ss.TotalSalesPrice,
ss.TotalSalesQuantity,
ss.TotalSalesDollars,
ss.TotalExciseTax,
fs.FreightCost
FROM PurchaseSummary ps
LEFT JOIN SalesSummary ss ON ps.VendorNumber = ss.VendorNo AND ps.Brand = ss.Brand
LEFT JOIN FreightSummary fs ON ps.VendorNumber = fs.VendorNumber
ORDER BY ps.TotalPurchaseDollars DESC
''',conn)

  end_time = time.time()
  total_time = (end_time - start_time) / 60
  print(f'Total time taken for ingestion: {total_time:.2f} minutes')
  return vendor_sales_summary

def clean_data(vendor_sales_summary):
  '''This function will clean the data'''

  #Changing data type to float
  vendor_sales_summary['Volume'] = vendor_sales_summary['Volume'].astype('float64')

  #Removing sapces from categorical columns
  vendor_sales_summary['VendorName'] = vendor_sales_summary['VendorName'].str.strip()
  vendor_sales_summary['Description'] = vendor_sales_summary['Description'].str.strip()

  #Filling missing values with zero
  vendor_sales_summary.fillna(0, inplace=True)

  #creating new features for better analysis
  vendor_sales_summary['GrossProfit'] = vendor_sales_summary['TotalSalesDollars'] - vendor_sales_summary['TotalPurchaseDollars']
  vendor_sales_summary['ProfitMargin'] = (vendor_sales_summary['GrossProfit'] / vendor_sales_summary['TotalSalesDollars']) * 100
  vendor_sales_summary['StockTrunover'] = vendor_sales_summary['TotalPurchaseQuantity'] / vendor_sales_summary['TotalSalesQuantity']
  vendor_sales_summary['SalesToPurchaseRatio'] = vendor_sales_summary['TotalSalesQuantity'] / vendor_sales_summary['TotalPurchaseQuantity']

  return vendor_sales_summary


if __name__ == "__main__":
  #Creating Database connection
  conn = sqlite3.connect('inventor.db')
  print("Opened database successfully")

  logging.info("Creating vendor_sales_summary table.....")
  print("Creating vendor_sales_summary table.....")
  summary_df = create_vendor_summary(conn)
  logging.info("Vendor_sales_summary table created successfully")
  print("Vendor_sales_summary table created successfully")
  logging.info(summary_df.head())
  print(summary_df.head())

  summary_df = clean_data(summary_df)

  logging.info('Cleaning Data....')
  print("Cleaning Data....")
  clean_df = clean_data(summary_df)
  logging.info("Data cleaned successfully")
  print("Data cleaned successfully")
  logging.info(clean_df.head())
  print(clean_df.head())

  logging.info("Inserting data into vendor_sales_summary table....")
  print("Inserting data into vendor_sales_summary table....")
  #Write the data into the table
  clean_df.to_sql('vendor_sales_summary', conn, if_exists='replace', index=False)
  logging.info("Data inserted into vendor_sales_summary table successfully")
  print("Data inserted into vendor_sales_summary table successfully")

vendor_sales_summary

"""# Final Exploratory Data Analysis

*   Previously, we examined the various tables in the database to identify key variables, understand their relationships, and determine which ones should be included in the final analysis.
*  In this of EDA, we will analyze the resultant table to gain insights into the distribution of each column. This will help us understand data patterns, identify anomalies, and ensure data quality before proceeding with further analysis.
"""

#summary statistics
summary_df.describe().T

#Distribution plots for numerical columns
import matplotlib.pyplot as plt
import seaborn as sns

numerical_columns = summary_df.select_dtypes(include=['int64', 'float64']).columns

plt.figure(figsize=(15, 10))
for i, column in enumerate(numerical_columns):
    plt.subplot(4, 4, i+1)
    sns.histplot(summary_df[column], kde=True, bins=30)
    plt.title(f'Distribution of {column}')
plt.tight_layout()
plt.show()

#Outlier Detection with Boxplots
plt.figure(figsize=(15, 10))
for i, column in enumerate(numerical_columns):
    plt.subplot(4, 4, i+1)
    sns.boxplot(y=summary_df[column])
    plt.title(f'Boxplot of {column}')
plt.tight_layout()
plt.show()

"""#Summary Statistics Insights

**Negative & Zero Values:**

*   Gross Profit: Minimun value is -52,002.78 indicating losses. Some products or transactions may be selling at a loss due to hight costs or selling at discounts lower than the purchase price.
*   Prodit Margin: Has a minimun of -infinity, which suggests cases where revenue is zero even lower than costs.
*   Total Sales Quantity & Sales Dollars: Minimun values are 0, meaning some products were purchased but never sold. These could be slow-moving or obsolete stock.

**Outliers Indicated by High Standard Deviations:**

*   Purchase & Actual Prices: The max values (5,681.81 & 7,499.99) are significantly higher than the mean (24.39 & 35.64), indicating potential premium products.
*   Freight Cost: Huge variation, from 0.09 to 257,032.07 suggests logistics inefficient or bulk shipments.
*   Stock Trunover: Ranges from 0 to 274.5, implying some products sell extremely fast while other remain in stock indefinitely. Value more than 1 indicates that Sold quantity for that product is higher than purchased quantity due to earlier sales are being fullfilled from the older stock.
"""

vendor_sales_summary

#Let's filter the data by removing inconsistencies
df = pd.read_sql_query('''
    SELECT * FROM vendor_sales_summary
    WHERE GrossProfit > 0
    AND ProfitMargin >= 0
    AND TotalSalesQuantity > 0
    ''',conn
)

df

#Distribution plots for numerical columns after cleaning the data
import matplotlib.pyplot as plt
import seaborn as sns

numerical_columns = summary_df.select_dtypes(include=['int64', 'float64']).columns

plt.figure(figsize=(15, 10))
for i, column in enumerate(numerical_columns):
    plt.subplot(4, 4, i+1)
    sns.histplot(summary_df[column], kde=True, bins=30)
    plt.title(f'Distribution of {column}')
plt.tight_layout()
plt.show()

# Count plots for Categorical Columns
categorical_columns = ['VendorName','Description']

plt.figure(figsize=(12, 5))
for i, column in enumerate(categorical_columns, 1):
    plt.subplot(1, len(categorical_columns), i)
    sns.countplot(y=df[column], order = df[column].value_counts().index[:10]) #Top 10 categories
    plt.title(f'Count Plot of {column}')
plt.tight_layout()
plt.show()

#Correlation Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df[numerical_columns].corr(), fmt = ".2f", annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""**Correlation Insights**

*   PurchasePrice has weak correlations with TotalSalesDollars(-0.012) and GrossProfit(-0.016), suggesting that price variations do not significantly impact sales revenue or profit.
*   Strong correlation between total purchase quantity and total sales quantity(0.99), confirming efficient inventory turnover.
*   Negative correlation between proft marign & total sales price(-0.179) suggests that as sales price increases, margin decreases, possibly due to competitive pricing pressure.
*   StockTrunover has weak negative correlations with both GrossProfit (-0.38) and ProfitmArgin(-0.055), indicating that fastest turnover dies not necessarily result in higher profitabilty.

#Data Analysis

**Identify Brands that needs Promotional or Pricing Adjustments which exhibit lower sales performance but higher profit margins.**
"""

brand_performance = df.groupby('Description').agg({
    'TotalSalesDollars':'sum',
    'ProfitMargin':'mean',
}).reset_index()

low_sales_threshold = brand_performance['TotalSalesDollars'].quantile(0.15)
high_margin_threshold = brand_performance['ProfitMargin'].quantile(0.85)

low_sales_threshold,high_margin_threshold

#Filter brands with low sales but high profit margins
target_brands = brand_performance[
    (brand_performance['TotalSalesDollars'] < low_sales_threshold) &
    (brand_performance['ProfitMargin'] > high_margin_threshold)
]

print("Brands with low sales but high profit margins:")
print(target_brands)

brand_performance = brand_performance[brand_performance['TotalSalesDollars'] < 10000] # For better visulization

plt.figure(figsize=(10, 6))
sns.scatterplot(data=brand_performance, x='TotalSalesDollars', y='ProfitMargin', color="blue", label="All Brands",alpha=0.2)
sns.scatterplot(data=target_brands, x='TotalSalesDollars', y='ProfitMargin', color="red", label="Target Brands")

plt.axhline(high_margin_threshold, linestyle='--', color='Black', label=f'High Margin Threshold ({high_margin_threshold:.2f})')
plt.axvline(low_sales_threshold, linestyle='--', color='Black', label=f'Low Sales Threshold ({low_sales_threshold:.2f})')
plt.title('Brands for Promotion or Pricing Adjustments')
plt.xlabel('Total Sales Dollars')
plt.ylabel('Profit Margin')
plt.legend()
plt.grid(True)
plt.show()

"""**Which vendors and brands demonstrate the highest sales performance?**"""

#Top vendors and brands by sales performance
top_vendors = df.groupby('VendorName')['TotalSalesDollars'].sum().nlargest(10)
top_brands = df.groupby('Description')['TotalSalesDollars'].sum().nlargest(10)
top_vendors,top_brands

def format_dollars(value):
  if value >= 1000000:
    return f'{value/1000000:.2f}M'
  elif value >= 1000 and value < 1000000:
    return f'{value/1000:.2f}K'
  elif value >= 1000:
    return f'{value:,.2f}'
  else:
    return str(value)

top_brands = top_brands.apply(format_dollars)
top_vendors = top_vendors.apply(format_dollars)

top_brands

top_vendors

plt.figure(figsize=(15, 5))

#Plot for top vendors
plt.subplot(1, 2, 1)
ax1 = sns.barplot(y=top_vendors.index, x=top_vendors.values, palette='Blues_r', hue=top_vendors.values, legend=False)
plt.title('Top 10 Vendors by Sales Performance')
plt.xlabel('Total Sales Dollars')
plt.ylabel('Vendor Name')


for bar in ax1.patches:
    ax1.text(bar.get_width() + (bar.get_width() * 0.02),
            bar.get_y() + bar.get_height()/2,
            format_dollars(bar.get_width()),
            va='center',ha='left', fontsize = 10, color="black")

#Plot top 10 brands
plt.subplot(1, 2, 2)
ax2 = sns.barplot(y=top_brands.index, x=top_brands.values, palette='Reds_r', hue=top_brands.values, legend=False)
plt.title('Top 10 Brands by Sales Performance')
plt.xlabel('Total Sales Dollars')
plt.ylabel('Brand Name')

for bar in ax2.patches:
    ax2.text(bar.get_width() + (bar.get_width() * 0.02),
            bar.get_y() + bar.get_height()/2,
            format_dollars(bar.get_width()),
            va='center',ha='left', fontsize = 10, color="black")

plt.tight_layout()
plt.show()

"""**Which vendors contibute the most to total purchase dollars?**"""

vendor_performance = df.groupby('VendorName').agg({
    'TotalPurchaseDollars':'sum',
    'GrossProfit':'sum',
    'TotalSalesDollars':'sum'
}).reset_index()

vendor_performance['PurchaseContribution'] = (vendor_performance['TotalPurchaseDollars'] / vendor_performance['TotalPurchaseDollars'].sum()) * 100

round(vendor_performance.sort_values('PurchaseContribution', ascending=False),2)

#Display top 10 Vendors
top_vendors = vendor_performance.nlargest(10, 'PurchaseContribution')
top_vendors['TotalSalesDollars'] = top_vendors['TotalSalesDollars'].apply(format_dollars)
top_vendors['TotalPurchaseDollars'] = top_vendors['TotalPurchaseDollars'].apply(format_dollars)
top_vendors['GrossProfit'] = top_vendors['GrossProfit'].apply(format_dollars)
top_vendors

top_vendors['PurchaseContribution'].sum()

top_vendors['Cumulative_Contribution%'] = top_vendors['PurchaseContribution'].cumsum()
top_vendors

fig, ax1 = plt.subplots(figsize=(10, 6))

#Bar plot for purchase Contribution%
sns.barplot(x=top_vendors['VendorName'], y = top_vendors['PurchaseContribution'], palette='mako', ax=ax1)

for i, value in enumerate(top_vendors['PurchaseContribution']):
  ax1.text(i, value - 1, f'{value:.2f}%', ha='center', va='bottom',color = "white")

#Line plot for cumulative contribution
ax2 = ax1.twinx()
ax2.plot(top_vendors['VendorName'], top_vendors['Cumulative_Contribution%'], color='red', marker='o', linestyle='-', label='Cumulative Contribution%')

ax1.set_xticklabels(top_vendors['VendorName'], rotation=90)
ax1.set_xlabel('Vendor Name')
ax1.set_ylabel('Purchase Contribution%', color='blue')
ax2.set_ylabel('Cumulative Contribution%', color='red')
ax1.set_title('Top 10 Vendors by Purchase Contribution%')

ax2.axhline(y=100,color='gray',linestyle='--',alpha = 0.7)
ax2.legend(loc='upper right')

plt.tight_layout()
plt.show()

"""**How much of total procurement is dependent on the top vendors?**"""

print(f'Total Purchase Contribution of top 10 vendors: {round(top_vendors["PurchaseContribution"].sum(),2)}%')

vendors = list(top_vendors['VendorName'].values)
purchase_contributions = list(top_vendors['PurchaseContribution'].values)
total_contribution = sum(purchase_contributions)
remaining_contribution = 100 - total_contribution

#Append "other Vendors" category
vendors.append("Other Vendors")
purchase_contributions.append(remaining_contribution)

#Donut Chart
fig, ax = plt.subplots(figsize=(8, 8))
wedges, texts, autotexts = ax.pie(purchase_contributions, labels=vendors, autopct='%1.1f%%',
                                  startangle=140, colors=sns.color_palette('mako', n_colors=len(vendors)))

#Draw a white circle in the center to create a "donut" effect
center_circle = plt.Circle((0, 0), 0.70, fc='white')
fig.gca().add_artist(center_circle)

#Add total contribution annotation in the center
plt.text(0,0, f"Top 10 Total:\n{total_contribution:.2f}%", fontsize = 14, fontweight = "bold", ha = "center", va = "center")

plt.title("Top 10 Vendors by Purchase Contribution%")
plt.show()

"""**Does purchasing in bulk reduce the unot price, and what is the optimal purchase volume for cost savings?**"""

df['UnitPurchasePrice'] = df['TotalPurchaseDollars'] / df['TotalPurchaseQuantity']

df

df['OrderSize'] = pd.qcut(df['TotalPurchaseQuantity'], q=3, labels=['Small', 'Medium', 'Large'])

df

df.groupby('OrderSize')[['UnitPurchasePrice']].mean()

#Plotting box plot
plt.figure(figsize=(10, 6))
sns.boxplot(x='OrderSize', y='UnitPurchasePrice', data=df, palette='mako')
plt.title('Box Plot of Unit Purchase Price by Order Size')
plt.xlabel('Order Size')
plt.ylabel('Unit Purchase Price')
plt.show()

"""*   Vendors buying in bulk (Large Order Size) get the lowest unit price ($10.78 per unit), meaning higher margins if they can manager incemtory efficiently.
*   The price difference between small and Lager orders is substantial (~72% reduction in unit cost)
*   This suggest that bulk pricing strategies successfully encourage vendors to purchase in large volumes, leading to higher overall sales despite lower per-unit revenue.

**Which vendors have low inventory turnover, indicating excess stock and slow-moving products?**
"""

df[df['StockTrunover'] < 1].groupby('VendorName')[['StockTrunover']].mean().sort_values('StockTrunover', ascending=True).head(10)

"""**How much capital is locked in unsold inventory per vendor, and which vendors contribute the most to it?**"""

df['UnsoldInventoryValue'] = (df['TotalPurchaseQuantity'] - df['TotalSalesQuantity']) * df['PurchasePrice']
print(f'Total Unsold Inventory Value:', format_dollars(df['UnsoldInventoryValue'].sum()))

#Aggregate Capital Locked per Vendor
inventory_value_per_vendor = df.groupby('VendorName')['UnsoldInventoryValue'].sum().reset_index()

#Sort vendors with the highest locked capitals
inventory_value_per_vendor = inventory_value_per_vendor.sort_values('UnsoldInventoryValue', ascending=False)
inventory_value_per_vendor['UnsoldInventoryValue'] = inventory_value_per_vendor['UnsoldInventoryValue'].apply(format_dollars)
inventory_value_per_vendor.head(10)

"""**What is the 95% confidence Intervals for Profit margins of top-performing and low-performing vendors.**"""

top_threshold = df['TotalSalesDollars'].quantile(0.75)
low_threshold = df['TotalSalesDollars'].quantile(0.25)

top_vendors = df[df['TotalSalesDollars'] >= top_threshold]['ProfitMargin'].dropna()
low_vendors = df[df['TotalSalesDollars'] <= low_threshold]['ProfitMargin'].dropna()

def confidence_interval(data, confidence=0.95):
  mean_val = np.mean(data)
  std_err = np.std(data, ddof=1) / np.sqrt(len(data)) #Standard error
  t_critical = stats.t.ppf((1+confidence)/2, df=len(data)-1)
  margin_of_error = t_critical * std_err
  lower_bound = mean_val - margin_of_error
  upper_bound = mean_val + margin_of_error
  return mean_val, lower_bound, upper_bound

import numpy as np
import scipy.stats as stats

top_mean, top_lower, top_upper = confidence_interval(top_vendors)
low_mean, low_lower, low_upper = confidence_interval(low_vendors)

print(f"Top Vendors 95% Confidence Interval: {top_lower:.2f}, {top_upper:.2f}, Mean: {top_mean: .2f}")
print(f"Low Vendors 95% Confidence Interval: {low_lower:.2f}, {low_upper:.2f},  Mean: {top_mean: .2f}")

plt.figure(figsize=(12, 6))

#Top vendors plot
sns.histplot(top_vendors, kde=True, bins=30, color='blue', label='Top Vendors')
plt.axvline(top_lower, color='red', linestyle='--', label='Lower Bound')
plt.axvline(top_upper, color='red', linestyle='--', label='Upper Bound')
plt.axvline(top_mean, color='red', linestyle='--', label='Mean')

#low vendor plot
sns.histplot(low_vendors, kde=True, bins=30, color='green', label='Low Vendors')
plt.axvline(low_lower, color='blue', linestyle='--', label='Lower Bound')
plt.axvline(low_upper, color='blue', linestyle='--', label='Upper Bound')
plt.axvline(low_mean, color='blue', linestyle='--', label='Mean')

#Finializing plot
plt.title('Confidence Intervals for Profit Margins')
plt.xlabel('Profit Margin')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True)
plt.show()

"""*   The CI for low-performing vendors (40.48% to 42.62%) is significantly higher than that of the top-performing vendors (30.74% to 31.61%).
*   This suggests that vendors with lower sales tend to maintain higher profit margins, potentially due to premium pricing or lower operational costs.
*   For High-Performing Vendors: If they aim to improve profitability, they could explore selective price adjustments, cost optimizations, or building strategies.
*   For Low-performing Vendors: Despite Higher margins, their low sales volume might indicate a need for better marketing, competitive pricing, or improved distribution strategies.

**Is there a significant difference in profit margins between top-performing and low-performing vendors?**

Hypothesis:

* Ho(Null Hypothesis): There is no significat difference in the mean profit margins of top-performing and low-performing vendors.
* Ha(Alternative Hypothesis): The mean profit margins of top-performing and low-performing vendors are significantly different.
"""

top_threshold = df['TotalSalesDollars'].quantile(0.75)
low_threshold = df['TotalSalesDollars'].quantile(0.25)

top_vendors = df[df['TotalSalesDollars'] >= top_threshold]['ProfitMargin'].dropna()
low_vendors = df[df['TotalSalesDollars'] <= low_threshold]['ProfitMargin'].dropna()

#Perform two-sample T-test
t_statistic, p_value = stats.ttest_ind(top_vendors, low_vendors, equal_var=False)

#Print results
print(f"T-statistic: {t_statistic:.4f} P-value: {p_value:.4f}")
if p_value < 0.05:
  print("Reject Null Hypothesis: There is a significant difference in profit margins between top and low-performing vendors.")
else:
  print("Fail to reject the Null Hypothesis: No Signifiact difference in profit Margin.")

"""#Final Insights for Business

**1. Optimizing Inventory and Capital Allocation**

*   **Insight:** A significant portion of capital is tied up in unsold inventory, especially with key vendors.

*   **Metric:** Total unsold inventory is valued at 2.71M Dollars, with top contributors including DIAGEO NORTH AMERICA INC 722K Dollars, JIM BEAM BRANDS COMPANY 555K Dollars, and PERNOD RICARD USA 471K Dollars.

*   **Business Impact:** Enables targeted stock reduction strategies to free up capital, improve inventory turnover, and enhance cash flow efficiency.


**2. Strategic Vendor Management for Procurement Efficiency**

*   **Insight:** A large share of procurement spending is concentrated among a few key vendors.

*   **Metric:** The top 10 vendors account for ~65.7% of total purchase value.

*   **Business Impact:** Emphasizes the need to strengthen vendor relationships to negotiate better terms, reduce costs, and build a resilient supply chain.


**3. Leveraging Bulk Purchasing for Cost Savings**

*   **Insight:** Larger purchase orders result in significant reductions in unit cost.

*   **Metric:** ~72% reduction in unit cost for bulk orders ($10.78) versus small orders 39.06 dollars.

*   **Business Impact:** Supports a strategy to prioritize bulk procurement, driving cost savings and improving profit margins.


**4. Targeted Sales & Marketing for High-Margin, Low-Sales Brands**

*   **Insight:** Some brands offer high margins but suffer from low sales volumes.

*   **Metric:** Identified 198 brands below the 15th percentile in sales and above the 85th percentile in profit margin.

*   **Business Impact:** Focused marketing on these brands can boost profitability without needing high sales volume, optimizing ROI.


**5. Differentiated Strategies for Vendor Profitability**

*   **Insight:** Profit margins vary significantly between low- and high-sales vendors.

*   **Metric:** Low-performing vendors show higher profit margins (40.5%–42.6%) compared to high-performing ones (30.7%–31.6%) at 95% confidence.

*   **Business Impact:** Recommends segmented vendor strategies—optimize volume and ops for high-sales vendors; explore pricing or promotion levers for low-sales, high-margin ones.
"""